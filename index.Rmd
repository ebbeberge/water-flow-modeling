---
title: "Modelling Water Flow with Shrinkage Methods"
author: "Rage Against The Machine Learning"
output:
  prettydoc::html_pretty:
    theme: hpstr

    highlight: github
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(data.table)
library(naniar)
library(reshape2)
library(ggplot2)
library(ggcorrplot)
library(h2o)
library(dplyr)
library(lubridate)
library(fastDummies)
library(glmnet)
library(leaps)
library(caret)
library(genlasso)
```

# Introduction

## Water Flow and Water Level

Statistical prediction of water flow (Norwegian: vannføring) and water level (Norwegian: vannstand) in rivers is an increasingly important problem. The problem is tightly linked with the prediction of floods. Because of climate change, the occurrence of floods is predicted to increase, and possibly in areas where floods have been historically rare:

[(Norwegian) Klima, nå og i framtiden](https://www.nve.no/klima/klima-na-og-i-framtiden/?ref=mainmenu)

Floods are potentially deadly for both humans and wildlife, and have huge economic consequences each year. Rivers are also an extremely important resource in many countries. In Norway, 90 % of produced electricity comes from hydropower:

[(Norwegian) Kraftproduksjon](https://energifaktanorge.no/norsk-energiforsyning/kraftforsyningen/)

Good statistical models for water flow and water level are important in order to optimize the production of electricity. The <i>Norwegian Water Resources and Energy Directorate (NVE)</i> has about 600 water level measurement stations all over Norway:

[(Norwegian) Stasjonsnettet](https://www.nve.no/hydrologi/vannstand-og-vannforing/stasjonsnettet/)

Measurements are going as far back as the 1940's. The <i>Norwegian Meteorological Institute (MET)</i> is responsible for the developed weather measurement and forecasting infrastructure in Norway. Many variables obtained by weather measurements, such as temperature, precipitation and snow content are traditionally used in physical models for water flow and water level. These physical models usually require parameter fitting and/or field experiments in order to yield good predictions. 

With the wealth of data available, it is worth considering purely data-driven approaches using measurements from NVE and MET to predict water flow and water level. In this report we will attempt to apply statistical shrinkage models to predict water flow at Eggafossen in Trøndelag, Norway. NVE was kind enough to give us water measurements and predictions from the model they are currently using, as well as weather data obtained from MET. 

## Eggafossen
Eggafossen is a location along the Gaula river in Trøndelag. Gaula as a whole is approximately 153 kilometers long and drains a watershed of about 3,661 square kilometers. The river runs through several populated areas as well as along the county road fv30, the highway E6, and the Rørosbanen train rail.

```{r pressure, echo=FALSE, fig.cap="Source: Google maps", out.width = '100%'}
knitr::include_graphics("images/eggafoss.png")
```

In 2011 there was a large flood in Trøndelag, mainly along the upper parts of Gaula. In particular, Ålen kommune, which is one of the largest population centers close to Eggafossen, suffered [large damages](https://www.dagbladet.no/nyheter/enorme-vannmasser-herjer-alen-sentrum/63582581). The Eggafoss station measured a water flow about 800 000 litres per second, whereas it normally measures about 20 000-30 000. Even though NVE has the responsibility of warning about floods, the 2011 flood was not predicted or warned about by NVE, and precautionary measurements were not taken. NVE stated in their own [report on the matter](https://publikasjoner.nve.no/dokument/2011/dokument2011_12.pdf):

>The risk of flood was underestimated because of several factors. The first percipitation predictions were too low. NVE's hydrological models were inadequate for the situation...

This motivates research on better prediction models.

## The HBV model

The [Hydrologiska Byråns Vattenbalansavdelig (HBV) model](https://en.wikipedia.org/wiki/HBV_hydrology_model) is a physical model designed for simulating river flow based on an advanced water balance calculation, specifically designed for rivers in Scandinavia.
The model is somewhat difficult to approach unless one has experience with hydrology, and we will not go into details here.

Because the HBV model most likely requires a data-driven fitting process, it is worth  asking: Is it possible to make comparable predictions to the HBV model 
using a purely data-driven model? The data driven model would have access to the same data
as the HBV model. If a purely data-driven model is shown to be as good or nearly as good as the HBV model, the model can easily be transferred to other measurement stations. Furthermore,
data-driven models can be used for inference in order to assess what actually causes water flow, and
can be used for confidence intervals and uncertainty measurements more easily than a physical model.

# Exploring the Data

The data from various .csv-files from NVE is gathered into the file `raw_data_eggafoss.rds`.

```{r}
# Importing data from Eggafoss
eggafoss = readRDS("data/raw_data_eggafoss.rds")

# Transform column names
names(eggafoss)[6:8] <- c("vannføring", "vannstand", "modellertvannføring")
names(eggafoss)
```

The data set consists of 8 features. They are all measured at 12:00 midday at the date of measurement.

- `dato`: date of measurements [yyyy-mm-dd]
- `nedbør`: rainfall [m]
- `snødekningsgrad`: snow coverage [%]
- `snøvannekvivalent`: snow's water equivalent [m]
- `temperatur`: temperature [°C]
- `vannføring`: water flow in river [m³/s]
- `vannstand`: water level in river [m]
- `modellertvannføring`: HBV's modelled water flow [m³/s]

We will use `vannføring` as the response. We begin by gauging basic information about the data.

```{r echo = FALSE}
str(eggafoss)
```

```{r echo = FALSE}
summary(eggafoss)
```

We notice that `dato` is given in Date-format, while the other feaures are numerical. Most features, like `nedbør`, `snødekningsgrad`, `vannføring`, `vannstand` og `modellertvannføring`, takes on numerical values greater or equal to zero, while `temperatur` can attain negative values as well. `snødekningsgrad` is given in percentage, so its range is between $0$ and $100$. The `dato` column shows that the collection of the data started in 1941 and goes all the up to the end of 2019, which means we have 78 years of daily data for some of our features. There also seems to be a lot of missing values is the dataset, which we will deal with below.

# Preprocessing and Exploratory Data Analysis

Before we can start fitting our data to different models, we have to preprosess the data and do some exploratory data analysis. The goal of this is making sure we have no missing values and that the data is transformed the way we want it, as well as get a initial feel for the features and their correlation with the response and with each other.

## Handling Missing values

From the summary of the data above, we see that we are missing some values. We make a plot of the missing values to see just how much we are missing.

```{r echo = FALSE}
naniar::vis_miss(eggafoss)
```

We see that we only have missing data for a certain range of dates. From 1941 to 1958 we only have data on `vannføring` and `vannstand`, but nothing else. Since there is not much use predicting `vannføring` only from `vannstand` before 1958, we decide to remove these years from the dataset.

```{r}
# Remove data between 1941 and 1958
eggafoss = eggafoss[6120:28764, ]

# Any NA's left?
any(is.na(eggafoss))
```

After removing the missing data we are left with 22645 observations from Eggafoss, which includes daily data from January 1st 1958 to December 31st 2019.

```{r, echo = FALSE}
dim(eggafoss)
```

```{r, include = FALSE}
head(eggafoss)
```

## Examining Correlation

Now that we have removed all the missing values, we start exploring some of the underlying features of the data. We start by looking at the correlation between the covariates and the response.

```{r, echo = FALSE}
# Calculate the correlation between the features
corr = cor(eggafoss[, 2:8])

# Plot the correlation
ggcorrplot(corr, hc.order = TRUE, type = "lower", lab = TRUE,
   outline.col = "white",
   ggtheme = ggplot2::theme_gray,
   colors = c("#6D9EC1", "white", "#E46726"))
```

We see that the response `vannføring` is mostly correlated with `modellertvannføring` and `vannstand`. We make a scatterplot of both of them against the response to see in more detail how they affect each other. To avoid to many points at once, we sample 3000 points from our data so that the underlying structure of the data becomes clearer. The orange line shows the linear regression line from the data.

```{r, message=FALSE, echo=FALSE}
# Extract 5000 samples
eggafoss_sample <- eggafoss[sample(nrow(eggafoss), 3000), ]

# Plot vannføring vs. modellertvannføring
ggplot(data = eggafoss_sample, aes(x = modellertvannføring, y = vannføring)) + 
  geom_point() +
  geom_smooth(colour = "orange", method = "lm") +
  labs(title = "Vannføring vs. modellertvannføring")
```

We see that `vannføring` and `modellertvannføring` are highly correlated, which is no big surprise since `modellertvannføring` is in fact the predicted value of `vannføring` from the HBV model. Thus it does not make sense for us to include this feature in our model. We will rather use the results from the HBV model as a baseline for the results from our own model, and see if we can improve on their results. 

```{r, message=FALSE, echo=FALSE}
# Plot vannføring vs. vannstand
ggplot(data = eggafoss_sample, aes(x = vannstand, y = vannføring)) + 
  geom_point() +
  geom_smooth(colour = "orange", method = "lm") +
  labs(title = "Vannføring vs. vannstand")
```

The height of water in a river is intuitively correlated with the amount of water flow in the river. Low water level, low water flow, and vice-versa. We see that the relationship is not linear. Using `vannstand` to predict `vannføring` is a little bit problematic from a practical point of view. If we want to model the predicted water flow in a river, we most likely would not have any measurements of the water level that day. The other features, like `temperatur` and `snødekningsgrad` could be inferred from good weather forecasting models, and thus would not pose the same practical problems. We conclude that when predicting the response, `vannstand` from the same day as the prediction will not be used.

We will also look at some of the covariates which have a high correlation with each other. This type of multicollinearity can cause problems in regular linear regression models, as it increases the standard error of the coefficients and thus some of the covariates can seem insignificant, even though they are not.

```{r, message=FALSE, echo=FALSE}
# Plot temperatur vs. snødekningsgrad
ggplot(data = eggafoss_sample, aes(x = temperatur, y = snødekningsgrad)) + 
  geom_point() +
  geom_smooth(colour = "orange", method = "lm") +
  labs(title = "Snødekningsgrad vs. temperatur")
# We see that there is a negative correlation between `snødekningsgrad` and `temperature`, which again hints at a seasonal pattern. Below -10°C the snow coverage is at 100%. It starts decreasing once the temperature increases and winter becomes summer.
```

The correlation between `temperatur` and `snødekningsgrad` is -0.73 and we see from the plot that there is a negative trend. Intuitively, the amount of snow decreases when the temperature increases. Below -10°C the snow coverage is at 100%. It starts decreasing once the temperature increases and winter becomes summer.  

Between `snødekningsgrad` and `snøvannekvivalent` there is also a strong correlation of 0.69. The more snow covers the ground, the more water is produced when the show melts. Since `snødekningsgrad` only gives us the percentage of the ground covered by snow, it stops at 100%, and thus will not give us a good indication of how much snow there actually is on the ground. `snøvannekvivalent` can provide a better measure of this. Since the values are so similar, both might not be needed in our model, and might be removed, or set close to zero, by the shrinkage methods.

```{r, message=FALSE, include=FALSE}
# Dont use this plot. We discard vannstand as predictor, so no use in mentioning it.
# Plot vannstand vs. temperatur
ggplot(data = eggafoss_sample, aes(x = temperatur, y = vannstand)) + 
  geom_point() +
  geom_smooth(colour = "orange", method = "lm") +
  labs(title = "Vannstand vs. temperatur")
#We see that there is a positive trend between `vannstand` and `temperature`. It is most clear in the temperature interval between -10°C and 5°C. This can indicate that `vannstand` is season-dependend, and that a high water level occurs in the spring. 
```

```{r, message=FALSE, include=FALSE}
# This plot becomes a little superfluous, so we remove it
# Plot snødekningsgrad vs. snøvannekvivalent
ggplot(data = eggafoss_sample, aes(x = snøvannekvivalent, y = snødekningsgrad)) + 
  geom_point() +
  geom_smooth(colour = "orange", method = "lm") +
  labs(title = "Snødekningsgrad vs. snøvannekvivalent")
```

## Understanding the Seasonality of the Response

One of the features of our original data set is `dato`, the date at which each observation is measured. We cannot use this feature directly in building our model, but based on the analysis above, it might be beneficial to add some information about the time of each measurement, as seasonality is present in the data. To make an even stronger argument of this we look the response `vannføring` as a time series.

```{r, message=FALSE, echo=FALSE}
# Time series of vannføring
ggplot(data = eggafoss, aes(x = dato, y = vannføring)) +
  geom_line() + 
  #geom_smooth(colour = "orange", method = "lm") + 
  labs(title = "Vannføring from 1958 to 2019")
```

From the plot above we see that there is definitely some trends in the data that repeats yearly. We take a closer look by making a boxplot of the `vannføring` for each month in a year. We would expect the water flow to usually be very low, with low variance, during the winter month. During spring and fall the average water flow should be a lot higher, and also have more variance.

```{r, include=FALSE}
# This plot is a little superfluous. Do not include it.
years = c(1960, 1980, 2000, 2019)

eggafoss %>%
  dplyr::mutate(year = factor(lubridate::year(dato))) %>%
  dplyr::filter(year %in% years) %>%
  ggplot() +
  geom_line(aes(x = lubridate::yday(dato), y = vannføring, group = year, col = year)) +
  ggtitle("Comparison of vannføring in 1960, 1980, 2000 and 2019") + 
  xlab("day")
```

```{r, echo=FALSE}
eggafoss %>%
  ggplot() +
  geom_boxplot(aes(group = lubridate::month(dato), x = lubridate::month(dato), y = vannføring)) + 
  ggtitle("Boxplot of monthly vannføring") + 
  xlab("month")
```

The boxplot shows what we expected. Based on the plot we make an argument that an interesting covariate to add to our model is `month`, which gives information about which month the observaion is from. We could also have chosen to include season instead of month, but because of the diffuculty to divide the pattern we see into seasons we might loose some information, and instead choose to do the finer monthly division. Adding more variables than necessary should not be a problem in this project, as the regularization methods will remove the variables which are not significant for the prediction of the response.

## Adding information about previous days
We will attempt to model the response `vannføring`, here denoted $y(t)$ with $t$ as a time variable at day $k$, as
$$ y(t_k) =  \sum_{i \in \text{covariates}}\sum_{j = 0}^\text{days} \beta_{i,j}x_i(t_{k - j}) + \sum_{j = 1}^\text{days} \beta_{\texttt{vannføring},j}x_\texttt{vannføring}(t_{k - j}),$$
where $x_i$ is a covariate in $\text{covariates} = [\texttt{nedbør}, \texttt{temperatur}, \texttt{snøvannekvivalent}, \texttt{snødekningsgrad}]$. The response `vannføring` is a linear combination of other covariates at the same and previous days, and also the the values of `vannføring` from previous days. This way our model will capture not only the relevant parameters from the same day (assuming we have a good weather forecast, so precipitation, temperature and snow is known), but relevant parameters from previous days. The motivation behind this approach is that, for rivers, we would expect the water flow to exhibit some delay in the response of the other covariates. For example, a heavy rainfall might lead to large water flow after a couple of days as it takes time for the rainfall to travel through the soil into the river. In addition, we would expect a large change in snow (melting) will lead to large water flow when this melted water reaches the river.

A linear combination of the same covariates over time can potentially capture not only the value of the data at previous days, but also the rate of change over previous days. It can also potentially extrapolate `vannføring` on the current day based on `vannføring` from the previous days.

We want to emphasize that a linear model might not be the best way to model the response in this example, but as the problem will include a lot of covariates, some of which are highly correlated, it hopefully makes sense to apply shrinkage models, which is the goal of this project. We should also mention that we use MSE as the error measure in this project. For a problem like this, where it is more important for our model to predict high water flow compared to low, there might be other error measures of interest as well.

```{r, echo=FALSE}
# Function which does all of the data preparation (also scaling and centering)

data_preparation = function(df, years, days) {
  
  # Only include specified years + 1 year for testing
  df = df %>% dplyr::filter(format(dato, "%Y") > (2019-years-3))
  
  # Which covariates we want to include
  doVannstand = FALSE
  doVannføring = TRUE
  doSnøvannekvivalent = TRUE
  doSnødekningsgrad = TRUE
  doNedbør = TRUE
  doTemperatur = TRUE
  
  sumDo = doVannstand + doSnøvannekvivalent + doSnødekningsgrad +
    doNedbør + doTemperatur + doVannføring
  names = length(names(df))
  
  # Extract information about previous days
  for (i in 1:days){
    len = length(df$dato)
    if (i == 1){
      do = 0
      if (doVannstand) {
        do = do + 1
        data = data.frame(c(NA,df$vannstand[1:(len-1)]))
        df = data.frame(c(df, data))
        name = paste("vannstand",i,"dager",sep="")
        names(df)[names+do] = name
      }
      if (doSnøvannekvivalent) {
        do = do + 1
        data = data.frame(c(NA,df$snøvannekvivalent[1:(len-1)]))
        df = data.frame(c(df, data))
        name = paste("snøvannekvivalent",i,"dager",sep="")
        names(df)[names+do] = name
      }
      if (doSnødekningsgrad) {
        do = do + 1
        data = data.frame(c(NA,df$snødekningsgrad[1:(len-1)]))
        df = data.frame(c(df, data))
        name = paste("snødekningsgrad",i,"dager",sep="")
        names(df)[names + do] = name
      }
      if (doNedbør) {
        do = do + 1
        data = data.frame(c(NA,df$nedbør[1:(len-1)]))
        df = data.frame(c(df, data))
        name = paste("nedbør",i,"dager",sep="")
        names(df)[names + do] = name
      }
      if (doTemperatur) {
        do = do + 1
        data = data.frame(c(NA,df$temperatur[1:(len-1)]))
        df = data.frame(c(df, data))
        name = paste("temperatur",i,"dager",sep="")
        names(df)[names + do] = name
      }
      if (doVannføring) {
        do = do + 1
        data = data.frame(c(NA,df$vannføring[1:(len-1)]))
        df = data.frame(c(df, data))
        name = paste("vannføring",i,"dager",sep="")
        names(df)[names + do] = name
      }
    }
    else {
      do = 0
      if (doVannstand) {
        do = do + 1
        data = data.frame(c(NA,df[1:(len-1), names + (i-2)*sumDo + do]))
        df = data.frame(c(df, data))
        name = paste("vannstand",i,"dager",sep="")
        names(df)[names+(i-1)*sumDo + do] = name
      }
      if (doSnøvannekvivalent) {
        do = do + 1
        data = data.frame(c(NA,df[1:(len-1), names + (i-2)*sumDo + do]))
        df = data.frame(c(df, data))
        name = paste("snøvannekvivalent",i,"dager",sep="")
        names(df)[names+(i-1)*sumDo + do] = name
      }
      if (doSnødekningsgrad) {
        do = do + 1
        data = data.frame(c(NA,df[1:(len-1), names + (i-2)*sumDo + do]))
        df = data.frame(c(df, data))
        name = paste("snødekningsgrad",i,"dager",sep="")
        names(df)[names+(i-1)*sumDo + do] = name
      }
      if (doNedbør) {
        do = do + 1
        data = data.frame(c(NA,df[1:(len-1), names + (i-2)*sumDo + do]))
        df = data.frame(c(df, data))
        name = paste("nedbør",i,"dager",sep="")
        names(df)[names+(i-1)*sumDo + do] = name
      }
      if (doTemperatur) {
        do = do + 1
        data = data.frame(c(NA,df[1:(len-1), names + (i-2)*sumDo + do]))
        df = data.frame(c(df, data))
        name = paste("temperatur",i,"dager",sep="")
        names(df)[names+(i-1)*sumDo + do] = name
      }
      if (doVannføring) {
        do = do + 1
        data = data.frame(c(NA,df[1:(len-1), names + (i-2)*sumDo + do]))
        df = data.frame(c(df, data))
        name = paste("vannføring",i,"dager",sep="")
        names(df)[names+(i-1)*sumDo + do] = name
      }
    }
  }
  
  # Remove the first days of the dataset where we don't have values for all the covariates
  df = na.omit(df)
  
  # Add month variable as factor
  df = df %>%
    dplyr::mutate(df, month = lubridate::month(dato))
  df$month = as.factor(df$month)
  
  # Make dummy variables
  df = fastDummies::dummy_cols(df, select_columns = "month",
                               remove_first_dummy = TRUE,
                               remove_selected_columns = TRUE)
  
  # Scale and center
  # Assuming date is always in the first column
  df[, -1] = scale(df[, -1], center = TRUE, scale = TRUE)
  
  # Split into training and test sets
  train = df %>% dplyr::filter(format(dato, "%Y") < 2018)
  test = df %>% dplyr::filter(format(dato, "%Y") >= 2018) 
  
  # Remove the first seven days of the test set, such that we get no leakage from the train set
  test = test[(days + 1):dim(test)[1], ]
  
  # Make data into model matrices
  x_train = model.matrix(vannføring~. -dato -vannstand -modellertvannføring, data = train)[,-1]
  y_train = train$vannføring
  
  x_test = model.matrix(vannføring~ .-dato -vannstand -modellertvannføring, data = test)[,-1]
  y_test = test$vannføring
  
  return(list(df, train, test, x_train, y_train, x_test, y_test))
}
```

# Modelling

We have chosen to use 40 years of data to train our model. Even though we have data from the last 60 years, we expect the quality of the data to have increased somewhat from 1958 to 2019, thus we find it unecessary to include all the data. We also think that 40 years of data should be sufficient to capture the underlying trends. We include data from the past 7 days as covariates, such that we might capture how snow melting, temperature change and percipitation can influence the response at a current date. If the later days do not influence the response, we hope that the models will detect this and remove them from the model.

We train on the observation between 1977 and 2017, and test the models on data from the years 2018 and 2019. The dimensions of the test and training set can be seen below. We will try to fit the data on traditional linear models, as well as some shrinkage methods to see which ones are best at prediction and inference. It is also of interest to see if we can beat HBV's modelled `vannføring` with our purely data-driven models.

All the data is standrdized and centered before we apply any of the models. Using the test and training sets described above the training set will consist of <b>14968</b> observations, while the test set will consist of <b>723</b> observations. After having removed `vannstand`, `modellertvannføring` and `dato`, as well as added covariates from previous days and months, we have <b>50</b> covariates.

```{r}
years = 40 # max 60, min 3 (since 2 years are automatically used for testing)
days = 7

# Function creates and splits dataset as discussed earlier ()
data = data_preparation(eggafoss, years, days) # See the markdown file for the function declaration
df = data[[1]]
train = data[[2]]
test = data[[3]]
x_train = data[[4]]
y_train = data[[5]]
x_test = data[[6]]
y_test = data[[7]]
```

## Traditional linear models

First we start of by fitting a linear model, a weighed linear model, and a best subset selection to our data. This is done such that we get an idea of which covariates might be significant to our model. Moreover, these methods then provide a benchmark for the shrinkage methods when it comes to prediction. We also hope that by using model selection we can increase the interpretability, and maybe also the prediction, of the linear model.

### Linear regression

We begin by fitting an the ordinary linear regression model:

```{r}
lm.fit = lm(vannføring~.-dato -vannstand -modellertvannføring, data = train)
summary(lm.fit)
```

As we can see, only a few of the covariates are significant in the model. The linear model explains around 93% of the variability in the data. One should not completely trust the coefficient estimates as we know some of the covariates are highly correlated. We make a prediction of the response with the test set, and calculate the MSE of the linear model as a baseline for the other models. We also calculate the MSE of the HBV model for comparison

```{r}
lm.pred = predict(lm.fit, test)
mean((test$vannføring - lm.pred)^2)
mean((test$vannføring - test$modellertvannføring)^2)
```

### Weighted linear regression

To make the linear model better adapted to the data, we introduce a weight that penalizes wrong predictions during the months where high water levels are common.

```{r}
# Initiate a weight that gives significant preference to months where high values for "vannstand" are appearing.
months_weight <- vector(length = dim(train)[1])
for (i in 1:dim(train)[1]) {
  if (train$month_4[i] > 0 | train$month_5[i] > 0 | train$month_6[i] > 0 | train$month_7[i] > 0 | train$month_9[i] > 0 | train$month_10[i] > 0) {
    months_weight[i] <- 50
  } else {
    months_weight[i] <- 1
  }
}
```

By fitting a weighted linear model, we get a lower MSE:

```{r echo=T, results='hide'}
weighted.lm.fit = lm(vannføring~.-dato -vannstand -modellertvannføring, data = train, weight = months_weight)
```

```{r}
summary(weighted.lm.fit)
weighted.lm.pred = predict(weighted.lm.fit, test)
(mean((test$vannføring - weighted.lm.pred)^2))
```

Notice that the adjusted R-squared statistic is almost 0.94, indicating that most of the variance in the data is accounted for by this model.

### Subset selection

We also want to see which variables a subset selection would choose, and if a linear model with these variables would preform better or as good as the linear model with all the covariates. We do both forward and backward selection, and choose the covariates which yields the smallect BIC and Cp values.

```{r}
# Subset model
fsub.fit = regsubsets(vannføring~ .-dato -vannstand -modellertvannføring, nvmax = 60, data = train, method="forward")

par(mfrow=c(2,2))

plot(summary(fsub.fit)$bic, xlab = "Number of Variables", ylab = "BIC", type = 'l', main = "BIC from Forward Selection")
l = which.min(summary(fsub.fit)$bic)
points(l, summary(fsub.fit)$bic[l], col="red", cex=2, pch=20)

plot(summary(fsub.fit)$cp, xlab = "Number of Variables", ylab = "Cp", type = 'l', main = "Cp from Forward Selection")
l = which.min(summary(fsub.fit)$cp)
points(l, summary(fsub.fit)$cp[l], col="red", cex=2, pch=20)

bsub.fit = regsubsets(vannføring~ .-dato -vannstand -modellertvannføring, nvmax = 60, data = train, method="backward")

plot(summary(bsub.fit)$bic, xlab = "Number of Variables", ylab = "BIC", type = 'l', main = "BIC from Backward Selection")
l = which.min(summary(bsub.fit)$bic)
points(l, summary(bsub.fit)$bic[l], col="red", cex=2, pch=20)

plot(summary(bsub.fit)$cp, xlab = "Number of Variables", ylab = "Cp", type = 'l', main = "Cp from Backward Selection")
l = which.min(summary(bsub.fit)$cp)
points(l, summary(bsub.fit)$cp[l], col="red", cex=2, pch=20)
```

We choose the covariates with the lowest BIC values from the backward selection.

```{r}
best = which.min(summary(bsub.fit)$bic)
coeffs = names(coef(bsub.fit, best))[2:length(coef(bsub.fit, best))]
train_subset = subset(train, select = c(coeffs))
train_subset["vannføring"] = train$vannføring

bestsub.fit = lm(vannføring~., data = train_subset)
summary(bestsub.fit)
```

We see that by using backward selection, the optimal model has 16 variables, which are all significant in the model. We observe that the temperature, amount of snow and amount of percipitation on the day of measurement are important, as well as the response value, precipitation, snow amount and temperature from some of the past days. Interestingly, the model does not care about the snow amount at day 3, 4, 5, or 6, but the snow amount at day 7 becomes significant. The same can be seen for some of the other covariates. This could just be our model fitting noise in the data, but might also point to a delay in the covariates impact on the response, which the model manages to catch. Using the model on the test set yields the following MSE:

```{r}
bestsub.pred = predict(bestsub.fit, test)
mean((test$vannføring - bestsub.pred)^2)
```

Notice that since all the traditional methods are ultimately linear regressions, it is straightforward to obtain inference about the coefficients in the models. As an example, one can easily find confidence intervals by using `confint()`.

The table below gives a summary of the three traditional methods. Notice that the intercept is not included when counting the variables in the last column of the table. Although the weighted linear regression outperforms the others in terms of predictive power, the subset selection is not far behind and have removed many non-significant variables.

```{r table2, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
tabl <- "
| Algorithm                  | Test MSE | Adjusted R-squared | Variables |
|----------------------------|:--------:|:------------------:|----------:|
| Linear Regression          | 0.0548   | 0.9321             | 50
| Weighted Linear Regression | 0.0514   | 0.9384             | 50
| Subset Selection           | 0.0541   | 0.9319             | 16
"
cat(tabl) # output the table in a format good for HTML/PDF/docx conversion
```

We can plot the prediction of `vannføring` from the linear model for the year 2019. Below we can see the prediction compared with the true `vannføring` and the `modellertvannføring` from the HBV model. We see that our prediction does a pretty good job at predicting the response. It manages to accurately predict the peaks of the water flow, just as well as, if not better, than the HBV model. The downside of the model is the variance, or "noise", of the prediction at the times where the water flow is at is lowest. We see that instead of giving a smooth prediction like HBV, the model varies wildy. A goal would be to decrease this variation in the prediction.

```{r echo=FALSE}
variable_vec = c("vannføring", "modellertvannføring", "lm")
#test_2019 = test %>% dplyr::filter(format(dato, "%Y") > 2018)
#pred = predict(lm.fit, test_2019)

test %>%
  dplyr::mutate(lm = lm.pred) %>%
  tidyr::pivot_longer(tidyselect::all_of(variable_vec)) %>%
  dplyr::mutate(name = factor(name, levels = variable_vec)) %>%
  ggplot(aes(x = dato, y = value, group = name, col = name, linetype = name)) +
  geom_line() +
  scale_color_manual(values = c("black", "blue", "red")) +
  labs(col = "legend", linetype = "legend")
```

## Shrinkage models

In the data set we have a lot of covariates, many of which are not significant for our model. This motivates the use for shrinkage, or regularization, methods. These types of methods utilize the underlying assumption of simplicity in our data set, namely that only a few of the predictors actually play an important role in uncovering the signal in the data. We hope that by utilizing these types of methods we can remove/reduce the coefficients of the excessive covariates, to improve the prediction and interpretability of the model.

### Lasso model

The first model we will look at is the Lasso. The Lasso is a shrinkage method which utilizes a $L_1$ penalty to shrink and remove some of the covariates in the model. The lasso coefficients are given by

$$ \hat{\beta}_{L} = \arg\min_{\beta} \left \{ \frac{1}{2}\sum_{i=1}^N (y_i - \beta_0 -\sum_{j=1}^p x_{ij}\beta_j)^2 + \lambda \sum_{j=1}^p |\beta_j| \right \},$$
where $N$ is the number of datapoints and $p$ is the number of covariates. To use this method we have to set the tuning parameter $\lambda$. One of the most common ways to do this is to do a cross validation. We will use the package glmnet's own implementation of cross validaton for choosing the optimal $\lambda$, using 10 folds.

```{r}
start = glmnet(x = x_train, y = y_train, alpha = 1, standardize = FALSE)
autolambda = start$lambda
lambdagrid = c(autolambda, 0.5, 0.3, 0.2, 0.1)

lasso.fit = glmnet(x = x_train, y = y_train, alpha = 1, lambda = lambdagrid, nfolds = 10, standardize = FALSE)
cvlasso.fit = cv.glmnet(x_train, y_train, alpha = 1, lambda = lambdagrid, nfolds = 10, standardize = FALSE)

plot(cvlasso.fit)
```

Above we see a plot of the MSE from the cross validation for the different values of $\lambda$. The first vertical bar shows the optimal $\lambda$, while the second bar shows the $\lambda$ one standard error above the minimal value. By choosing the one standard error $\lambda$ we will choose a slightly simpler model, whose error is still within one standard error of the minimal one. From the plot it does not seem like a heavily regularized method will preform better than a full linear model. The optimal lambda value is very close to zero, meaning that there is almost no regularization of the coefficients happening. Since we have a lot of training data, the confidence intervals are tight. We calculate the test MSE for the different $\lambda$ values, as well as for $\lambda$ equal to 0 and 0.005.

```{r, include=FALSE}
for (i in c(0, cvlasso.fit$lambda.min, cvlasso.fit$lambda.1se, 0.005)) {
  lasso = glmnet(x = x_train, y = y_train, alpha = 1, lambda = i, nfolds = 10, standardize = FALSE)
  pred = predict(lasso, s=i, newx = x_test)
  
  print(paste("Lambda: ", i))
  print(paste("Test MSE: ", mean((y_test - pred)^2)))
  print(paste("Number of non-zero coeffs: ", lasso$df))
  print(" ")
}
```

```{r table3, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
table <- "
| Lambda      | Test MSE | Variables | 
|-------------|:--------:|:---------:|
| 0.00000000  | 0.0565   | 50              
| 0.00009324  | 0.0573   | 42              
| 0.00065779  | 0.0684   | 35              
| 0.00500000  | 0.0960   | 16           
"
cat(table) # output the table in a format good for HTML/PDF/docx conversion
```

We see that as expected, $\lambda = 0$ yields the smallest test MSE. As $\lambda$ increases the test MSE increases. To gain the same number of non-zero coefficients as in the backward subset model, we have to use a $\lambda$ value of around 0.005. This yields a test MSE of 0.0960, which is an increase of the subset test MSE. We also meantion that the reason the $\lambda$ values are all very small, i.e. close to zero, is because we have standardized the data outside of the model. We take a look at the coefficients chosen by each model, for the minimum and 1se $\lambda$, as well as $\lambda = 0.005$:

```{r}
coefficients = cbind(coef(lasso.fit, s = cvlasso.fit$lambda.min), coef(lasso.fit, s = cvlasso.fit$lambda.1se), coef(lasso.fit, s = 0.005))
colnames(coefficients) = c("lambda min", "lambda 1se","lambda 0.005")
print(coefficients)
```

We see that most of the values removed by the less penalized methods are also removed in the more penalized methods. For the coefficients set to zero in the most penalized model, we see a decrease in the coefficient value between the model with the minimum lamda and the 1se lambda, which is what we expect. Some of the covariates that are set to zero in the less penalized methods, like `snøvannekvivalent6dager` and `snøvannekvivalent7dager`, are not removed in the most penalized method, which is a little bit strange. One of the downsides to lasso is that groups of highly correlated variables can make the performance bad, and the coefficient paths can show some weird behavior. We look at a plot of the coefficients for the different $\lambda$s.

```{r}
plot(lasso.fit, xvar = "lambda", label = TRUE)
abline(v=log(cvlasso.fit$lambda.min))
abline(v=log(cvlasso.fit$lambda.1se))
abline(v=log(0.005))
```

We see that some of the coefficients decrease and then increase again. This might indicate that Lasso is not suitable for our problem.

From a pure prediction point of view, the best model would be the one yielding the smallest test MSE, which is the one with the smallest $\lambda$ value.

```{r}
cvlasso.pred = predict(lasso.fit, s = cvlasso.fit$lambda.min, newx = x_test)
mean((y_test - cvlasso.pred)^2)
```

Choosing this model we get a test MSE very similar to the linear regression model, used 8 variables less. We still have 42 variables in our model, which makes interpretability of the model difficult. We want a smaller subset of variables to get information about which of our predictors are most important, which can help us identify the causes of floods at Eggafoss. For this purpose it would be better to choose the model with $\lambda = 0.005$. It gives a decrease in prediction power for the increase in interpretability.

In the traditional linear models studied above it is easy to determine the significance of the included variables. Doing this for the Lasso proves more of a challenge. One way to do this is to use the Bayesian lasso, which will give us the posterior distributions for the $\beta_j$ in the model. Another is to use bootstrapping. Since we have enough data to have a separate test set, we will use a slightely simpler method where we use the selected covariates from lasso in a linear model, fitted on the test data. From this we can get an estimate of the p-value and confidence interval of the coefficients $\beta_j$. In this way lasso is only used for model selection, while a linear regression model is used for the model assessment. We will use the 16 variables chosen by the lasso model with $\lambda = 0.005$.

```{r}
#coef(lasso.fit, s = 0.005)
coeffs = c("nedbør", "temperatur", "snødekningsgrad1dager", "nedbør1dager",
           "vannføring1dager", "nedbør2dager", "vannføring2dager", "temperatur3dager",
           "snøvannekvivalent6dager", "snøvannekvivalent7dager",
           "month_2", "month_3", "month_5", "month_6", "month_9", "month_10")

lasso_subset = subset(test, select = c(coeffs))
lasso_subset["vannføring"] = test$vannføring

inference.fit = lm(vannføring~., data = lasso_subset)
summary(inference.fit)
```

We see that only about half of the 16 covariates have a p-value which would be considered significant. We can also look at the 95% confidence intervals below.

```{r}
confint(inference.fit, level = 0.95)
```

For the significant variables, the 95% confidence intervals seem good as they tightly fit the data. For all the non-significant variables, the confidence intervals all include 0, which implies that these are perhaps not the best subset of predictors. All of this indicates that lasso might not be the best method for our type of temporal data.

We also plot the prediction of `vannføring` from the lasso model with $\lambda_{min}$ from the cv for the year 2018 and 2019. We see that the prediction is very similar to the one from the linear model, which is not surprising given that the models are very similar. The regularized method did not manage to decrease the variability in the predition at the lower water levels.

```{r echo=FALSE}
variable_vec = c("vannføring", "modellertvannføring", "lasso")

pred = predict(lasso.fit, s = cvlasso.fit$lambda.min, newx = x_test)

test %>%
  dplyr::mutate(lasso = pred) %>%
  tidyr::pivot_longer(tidyselect::all_of(variable_vec)) %>%
  dplyr::mutate(name = factor(name, levels = variable_vec)) %>%
  ggplot(aes(x = dato, y = value, group = name, col = name, linetype = name)) +
  geom_line() +
  scale_color_manual(values = c("black", "blue", "orange")) +
  labs(col = "legend", linetype = "legend")
```

### Elastic net model

We have seen that the normal lasso with the $L_1$ penalty was not well suited for our data in terms of prediction power. We therefore consider some generalizations of the lasso, obtained by varying the loss function. By comparing the $L_1$ and $L_2$ penalty we obtain the elastic net method. This method might deal better with the correlated groups in our data. The elastic net coefficients are given by

$$ \hat{\beta}^{elastic \ net} = \arg\min_{\beta} \left \{ \frac{1}{2}\sum_{i=1}^N (y_i - \beta_0 -\sum_{j=1}^p x_{ij}\beta_j)^2 + \lambda \sum_{j=1}^p ((1-\alpha)\beta_j^2 + \alpha|\beta_j|) \right \},$$

where $\alpha$ is a parameter between 0 and 1. If $\alpha = 1$, the problem is reduced to the normal lasso, while if $\alpha = 0$ we have the ridge regression. We use the package `caret` to do a grid search over both $\alpha$ and $\lambda$, to find the optimal elastic net model. To do this we use a cross validation with 10 folds, and repeat the cross validation 5 times to obtain less variance in the cross validation error. We exclude 1 from the possible $\alpha$ values, to stop the model for choosing a pure lasso.

```{r}
control <- trainControl(method = "repeatedcv", 
                              number = 5, 
                              repeats = 5, 
                              search = "random")

elastic_model <- train(vannføring~.-dato -vannstand -modellertvannføring, 
                       data = train, 
                       method = "glmnet",
                       tuneLength = 25,
                       trControl = control) 

elastic_model
```

From the cross validation results $\alpha =$ `r elastic_model$bestTune$alpha` and $\lambda =$ `r elastic_model$bestTune$lambda` are chosen as the optimal values yielding the lowest RMSE. Normally, we should be careful simply choosing the parameters yielding the smallest error, as there could still be some overfitting happening even though the risk of this is mitigated some when using cross validation. In this case we have a lot of training data from many years, and we don't expect the variance in the data between the training years is any smaller than for normal years. We would therefore not expect much overfitting during our fitting, especially not for non-flexible models like elastic net.

The chosen $\alpha$ values hints at a model closest to lasso, but with some of the $L_2$ penalty from the ridge also. Since $\lambda$ is still very close to zero, the effect of the penalization are small, and we do not expect a much better model than the linear one. We calculate the test MSE.

```{r}
elastic.fit = glmnet(x = x_train, y = y_train, alpha = elastic_model$bestTune$alpha, lambda = elastic_model$bestTune$lambda, standardize = FALSE)

elastic.pred = predict(elastic.fit, s = elastic_model$bestTune$lambda, newx = x_test)
mean((y_test - elastic.pred)^2)
```

The value is higher than the error from the lasso with the smallest optimal $\lambda$ value. It also includes more variables, which we see as a setback in this problem, as we do not think all `r elastic.fit$df` variables are needed to explain most of the variability in the response. We conclude that an elastic net model does not perform better than lasso for our observations, and that both have proven not suitable for our temporal problem.

Since we have a temporal aspect to our data, we might wish for continuity in time-neighboring coefficients. The fused lasso is a method naturally tailored to such situations.

### Generalized lasso variants - Fused lasso
We can generalize the lasso to imbue our model with more specific properties. The generalized lasso is defined by HTW (https://web.stanford.edu/~hastie/StatLearnSparsity/) as

$$
 \hat{\beta}_{GL} = \arg\min_{\beta} \frac{1}{2} \|Y - X\beta\|_2^2 + \lambda \|D\beta\|_1,
$$
for some linear operator $D$ and regularization parameter $\lambda$. Here we also use a slightly more compact notation than earlier. The range of $D$ should be some space where we wish to look for a sparse solution. If we chose $D = I$, we arrive at the normal lasso. If we select $D$ as a difference matrix, i.e a matrix with $1$ on the diagonal, $-1$ on upper diagonal and $0$ elsewhere, we arrive at the so-called fused lasso.
The fused lasso can be suited for problems with some notion of time or space relationship. In this case it can select $\beta$ that are more piece-wise constant with respect to time or space, which means the resulting linear model will be piece-wise smoother in time or space. As the regularization parameter $\lambda$ increases, the resulting linear model a model where all components of $\beta$ have the same values. 

In our previous models we have seen that linear models will produce "noisy", non-smooth predictions, especially for low prediction values. It is therefore worth investigating a fused lasso model to see if we can achieve a smoother model, hopefully without losing prediction power. 
Unlike the fused lasso described above, each of our covariates $\text{covariates} = [\texttt{vannføring}, \texttt{nedbør}, \texttt{temperatur}, \texttt{snøvannekvivalent}, \texttt{snødekningsgrad}]$ with their corresponding covariates backwards in time have a relationship in time, but not a relationship we want to shrink between themselves. We therefore select the matrix $D$ so that the resulting fused lasso model becomes
$$
\hat{\beta}_{FL} = \arg\min_{\beta} \frac{1}{2} \|Y - X\beta\|_2^2 + \lambda \sum_{i \in \text{covariates}} \sum_{j=0}^\text{days-1} | \beta_{i,j} - \beta_{i,j+1}|.
$$
We use the R package `genlasso` to fit our fused lasso model. This package does not
have a built in parameter selection method, but rather returns different fits for a range of parameters $\lambda$. This parameter could be chosen by the methods discussed earlier in this text,
but for now we are more interested in what type of fits we obtain for different parameters $\lambda$. We can also extend the fused lasso model by adding an additional penalty term $\gamma \|\beta\|_1$ for some $\gamma > 0 $ to also shrink the parameters similarly to normal lasso. However, we have seen so far that full linear models perform well on this problem, and we do not apply this additional penalty term.
We fit the described fused lasso model to the training set similarly as earlier methods and test
the method for different parameters $\lambda$ on a test set.


```{r, echo = FALSE, message = FALSE}
n = length(x_train[1,])
main_diag = rep(1,n)

#Remove months
main_diag[4 + (days-1)*5 + 1:n] = 0
D = bandSparse(n, k = 0, diagonals = matrix(main_diag))

# For the love of god don't change this
# 4 is the amount of original covariates
# i.e temperatur, nedbør, snø + snø
D[1,4 + 3] = -1
D[2,4 + 2] = -1
D[3,4+1] = -1
D[4,4 + 4] = -1
for (i in 1:5){
  for (j in 1:(days-1)){
    #D[days*j + i] = 0
    D[4 + (j-1)*5 + i, 4 + j*5 + i] = -1 
  }
}
```

```{r, message = FALSE}
# D matrix as described earlier
fusedLasso = fusedlasso(y_train,x_train,D, gamma = 0.0,maxsteps=10000)
nlam = length(fusedLasso$lambda)

newy = predict.genlasso(fusedLasso,Xnew=x_test)
testMSE = rep(0,nlam)
for (i in 1:nlam){
  newyfit = newy$fit[,i]
  testMSE[i] = mean((test$vannføring - newyfit)^2)
}

qplot(x = log(fusedLasso$lambda), y = testMSE) + ggtitle("Fused Lasso testMSE vs. lambda") + xlab("log(lambda)") + ylab("testMSE")
```

The resulting plot of test MSE versus regularization parameter is very similar to the similar plot for normal lasso, except this time we use an actual test MSE instead of a cross-validation statistic. We see that in order to obtain a model with good prediction properties, we want almost no regularization. This is not particularly interesting to us, as this model is nearly indistinguishable from a linear model. Instead, in order to investigate some of the properties of a fused lasso model, we choose a model with high $\lambda$, which has over double the test MSE of the standard linear model.

```{r}
newyfit = newy$fit[,6]
FLbeta = fusedLasso$beta[,6]
testMSE[6]
names = names(train)
names = names[! names %in% c("vannføring","vannstand","modellertvannføring","dato")]
names(FLbeta) = names
FLbeta
```
Inspecting the chosen coefficients we see that none of them are $0$ as expected. To keep things readable we print only the \texttt{nedbør} variables:
```{r}
FLbeta[c("nedbør", "nedbør1dager", "nedbør2dager", "nedbør3dager", "nedbør4dager", "nedbør5dager", "nedbør6dager", "nedbør7dager")]
```
What we see is that the variables for days $1-7$ are piece-wise constant, which is an effect we would expect from the fused lasso. We also see, as we have seen before, that the \texttt{nedbør} from the same day has the largest effect on the prediction. We can thus use the fused lasso to study the time relationship 

We plot the prediction on part of the test set.
```{r}
# Rekkefølge på ting som skal plottes
variable_vec = c("vannføring", "modellertvannføring", "fusedlasso")

test %>%
  dplyr::mutate(fusedlasso = newyfit) %>%
  tidyr::pivot_longer(tidyselect::all_of(variable_vec)) %>%
  dplyr::mutate(name = factor(name, levels = variable_vec)) %>%
  ggplot(aes(x = dato, y = value, group = name, col = name, linetype = name)) +
  geom_line() +
  scale_color_manual(values = c("black", "blue", "green")) +
  labs(col = "legend", linetype = "legend")
```

While the resulting prediction is perhaps a tiny bit smoother than the standard linear model, in particular when \texttt{vannføring} is relatively low. This comes at the cost of the predictions for high \texttt{vannføring} becomes worse. This is somewhat contrary to the standard linear model,
where accuracy for high \texttt{vannføring} comes at the cost of high variance for low \texttt{vannføring}.

# Comparison and conclusion

We will now attempt to summarize and discuss some of our results. It is quite remarkable that linear models work so efficiently on this problem.
One would think that a standard linear model would have too high variance to be of any use. Furthermore, one would expect that a simple linear model would be unable to capture the non-linearities and dependence in the data. However, for this specific data set, linear models seem to outperform the existing HBV model when measuring MSE. Furthermore, linear models allow for inference and calculation of confidence intervals to a greater degree than a purely physical model. It is somewhat disappointing that more sophisticated models like the lasso and the fused lasso do not outperform standard linear regression, but we have seen that they can have some useful properties.

When that is said, there are some parts of our modeling and application of linear models that should be more looked into:

- The assumption that we have information about `temperatur`, `nedbør`, `snødekningsgrad` and `snøvanninnhold` from the same day, or even the previous days, when we are predicting `vannføring` is unlikely. We have imagined that this data is obtained from separate models. However, the linear models we have applied do not necessarily capture the extra uncertainty introduced by additional models. This is a big hurdle to overcome if such models are to be used in practice.

- How many days backwards in time should be included in a linear model? Using more data leads to larger, possibly overfitted and "bloated" models. This also introduces some data leakage in models where methods similar to cross validation is used for parameter selection. Linear models are relatively cheap to compute, but computation time should also be taken into account as the size of the linear models increase.

- How much data should be trained and tested on? This is a problem for all data-driven models, which also includes the HBV model. In general, useful available data should improve a learned model. However, the data in this case goes far back in time, and it is possible that not all data is reliable and that the river we are trying to model changes over time.

- Can similar models be applied to other locations, or is Eggafoss a special case? It is not clear if a similar approach will give similar results for other locations. It is possible that linear models are ineffective at other locations, and that some locations require shrinked models in order to be effective. When considering more than one location, it could also be interesting to see if there is some statistical relationship between several locations.

- We have seen that purely data-driven models has potential for predicting water flow. It is worth investigating more advanced models?

We summarize our results in the following table.

```{r table4, echo=FALSE, message=FALSE, warnings=FALSE, results='asis'}
tabl <- "
| Model                 | Test MSE | Properties             | 
|-----------------------|:--------:|:------------------:|:---------------------:|
| HBV                   | 0.1670         | Smooth model.
| Linear model          | 0.0548    | Large variance for low `vannføring`.
| Weighted linear model | 0.0514   | Large variance for low `vannføring`.
| Backward selection    | 0.0541    | Sparse model.
| Lasso                 | 0.0580    | Sparse model.
| Elastic net           | 0.0819    | Sparse model.
| Fused lasso (high regularization) | 0.1891      | Smooth(er) model.
"
cat(tabl) # output the table in a format good for HTML/PDF/docx conversion
```